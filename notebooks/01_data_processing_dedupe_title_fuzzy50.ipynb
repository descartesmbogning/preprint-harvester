{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb639d47-f553-42d6-b041-e35381e452ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Set option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bccf72-682d-4cc3-a5a4-91d1da4036a9",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bf7c65-5ff4-49e3-bc4f-30516bba9e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>server_name</th>\n",
       "      <th>backend</th>\n",
       "      <th>doi</th>\n",
       "      <th>doi_url</th>\n",
       "      <th>landing_page_url</th>\n",
       "      <th>title</th>\n",
       "      <th>authors_flat</th>\n",
       "      <th>institutions_flat</th>\n",
       "      <th>countries_flat</th>\n",
       "      <th>relations_json</th>\n",
       "      <th>version_label</th>\n",
       "      <th>is_version_of</th>\n",
       "      <th>is_preprint_of</th>\n",
       "      <th>has_preprint</th>\n",
       "      <th>has_review</th>\n",
       "      <th>has_published_version</th>\n",
       "      <th>published_version_ids_json</th>\n",
       "      <th>version_of_ids_json</th>\n",
       "      <th>update_to_json</th>\n",
       "      <th>raw_relationships_json</th>\n",
       "      <th>records_hierarchy</th>\n",
       "      <th>date_first_seen</th>\n",
       "      <th>publication_year_first_seen</th>\n",
       "      <th>parent_record_id</th>\n",
       "      <th>records_hierarchy_copy</th>\n",
       "      <th>dup_group_id</th>\n",
       "      <th>authors_fp_tokenbag</th>\n",
       "      <th>title_clean_v2</th>\n",
       "      <th>authors_fp_last_initial</th>\n",
       "      <th>authors_fp_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crossref::10.21467/preprints.48</td>\n",
       "      <td>AIJR Preprints</td>\n",
       "      <td>crossref</td>\n",
       "      <td>10.21467/preprints.48</td>\n",
       "      <td>https://doi.org/10.21467/preprints.48</td>\n",
       "      <td>https://preprints.aijr.org/index.php/ap/prepri...</td>\n",
       "      <td>Bird’s Eye View on the Diagnosis, Treatment, &amp;...</td>\n",
       "      <td>Panchalingala, Sai Bhargavi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crossref::10.21467/preprints.43</td>\n",
       "      <td>AIJR Preprints</td>\n",
       "      <td>crossref</td>\n",
       "      <td>10.21467/preprints.43</td>\n",
       "      <td>https://doi.org/10.21467/preprints.43</td>\n",
       "      <td>https://preprints.aijr.org/index.php/ap/prepri...</td>\n",
       "      <td>Doxycycline and Minocycline Drugs as a Treatme...</td>\n",
       "      <td>Mostafa, Mohamed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>mohamed_mostafa</td>\n",
       "      <td>doxycycline and minocycline drugs as a treatme...</td>\n",
       "      <td>mostafa|m</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crossref::10.21467/preprints.39</td>\n",
       "      <td>AIJR Preprints</td>\n",
       "      <td>crossref</td>\n",
       "      <td>10.21467/preprints.39</td>\n",
       "      <td>https://doi.org/10.21467/preprints.39</td>\n",
       "      <td>https://preprints.aijr.org/index.php/ap/prepri...</td>\n",
       "      <td>A Genetic Perspective of 2019-nCoV in Relation...</td>\n",
       "      <td>Dasgupta, Rimjhim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>dasgupta_rimjhim</td>\n",
       "      <td>a genetic perspective of 2019 ncov in relation...</td>\n",
       "      <td>dasgupta|r</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crossref::10.21467/preprints.38</td>\n",
       "      <td>AIJR Preprints</td>\n",
       "      <td>crossref</td>\n",
       "      <td>10.21467/preprints.38</td>\n",
       "      <td>https://doi.org/10.21467/preprints.38</td>\n",
       "      <td>https://preprints.aijr.org/index.php/ap/prepri...</td>\n",
       "      <td>Marine Algae as a Natural Source for Antiviral...</td>\n",
       "      <td>Musale, Amar S; G., Raja Krishna Kumar; Sapre,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crossref::10.21467/preprints.36</td>\n",
       "      <td>AIJR Preprints</td>\n",
       "      <td>crossref</td>\n",
       "      <td>10.21467/preprints.36</td>\n",
       "      <td>https://doi.org/10.21467/preprints.36</td>\n",
       "      <td>https://preprints.aijr.org/index.php/ap/prepri...</td>\n",
       "      <td>Possible Prevention of COVID 19 by Using Linol...</td>\n",
       "      <td>Subhash, Venkata; G, Raja Krishna Kumar; Sapre...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410089</th>\n",
       "      <td>openalex::W999325625</td>\n",
       "      <td>viXra</td>\n",
       "      <td>openalex</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vixra.org/pdf/1409.0090v1.pdf</td>\n",
       "      <td>Three Objections to Modern Physics</td>\n",
       "      <td>Lubomir Vlcek</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>lubomir_vlcek</td>\n",
       "      <td>three objections to modern physics</td>\n",
       "      <td>vlcek|l</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410090</th>\n",
       "      <td>openalex::W999460032</td>\n",
       "      <td>viXra</td>\n",
       "      <td>openalex</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vixra.org/abs/1112.0094</td>\n",
       "      <td>Particle Mass Ratios</td>\n",
       "      <td>DT Froedge</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>2011</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>dt_froedge</td>\n",
       "      <td>particle mass ratios</td>\n",
       "      <td>froedge|d</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410091</th>\n",
       "      <td>openalex::W99967155</td>\n",
       "      <td>viXra</td>\n",
       "      <td>openalex</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vixra.org/pdf/1406.0019v1.pdf</td>\n",
       "      <td>Quantum FFF Theory Proposals for Some Unsolved...</td>\n",
       "      <td>Leo Vuyk</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>leo_vuyk</td>\n",
       "      <td>quantum fff theory proposals for some unsolved...</td>\n",
       "      <td>vuyk|l</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410092</th>\n",
       "      <td>openalex::W999790414</td>\n",
       "      <td>viXra</td>\n",
       "      <td>openalex</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vixra.org/pdf/1306.0105v3.pdf</td>\n",
       "      <td>Investigation of the Formalism of Particle Dyn...</td>\n",
       "      <td>Chi-Yi Chen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>chen_chi_yi</td>\n",
       "      <td>investigation of the formalism of particle dyn...</td>\n",
       "      <td>chen|c</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8410093</th>\n",
       "      <td>openalex::W999805801</td>\n",
       "      <td>viXra</td>\n",
       "      <td>openalex</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://vixra.org/pdf/1412.0197v3.pdf</td>\n",
       "      <td>Electromagnetic Energy and Electromagnetic For...</td>\n",
       "      <td>Yu.A. Spirichev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>None</td>\n",
       "      <td>parent</td>\n",
       "      <td>None</td>\n",
       "      <td>a_spirichev_yu</td>\n",
       "      <td>electromagnetic energy and electromagnetic for...</td>\n",
       "      <td>spirichev|y</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8410094 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               record_id     server_name   backend  \\\n",
       "0        crossref::10.21467/preprints.48  AIJR Preprints  crossref   \n",
       "1        crossref::10.21467/preprints.43  AIJR Preprints  crossref   \n",
       "2        crossref::10.21467/preprints.39  AIJR Preprints  crossref   \n",
       "3        crossref::10.21467/preprints.38  AIJR Preprints  crossref   \n",
       "4        crossref::10.21467/preprints.36  AIJR Preprints  crossref   \n",
       "...                                  ...             ...       ...   \n",
       "8410089             openalex::W999325625           viXra  openalex   \n",
       "8410090             openalex::W999460032           viXra  openalex   \n",
       "8410091              openalex::W99967155           viXra  openalex   \n",
       "8410092             openalex::W999790414           viXra  openalex   \n",
       "8410093             openalex::W999805801           viXra  openalex   \n",
       "\n",
       "                           doi                                doi_url  \\\n",
       "0        10.21467/preprints.48  https://doi.org/10.21467/preprints.48   \n",
       "1        10.21467/preprints.43  https://doi.org/10.21467/preprints.43   \n",
       "2        10.21467/preprints.39  https://doi.org/10.21467/preprints.39   \n",
       "3        10.21467/preprints.38  https://doi.org/10.21467/preprints.38   \n",
       "4        10.21467/preprints.36  https://doi.org/10.21467/preprints.36   \n",
       "...                        ...                                    ...   \n",
       "8410089                   None                                   None   \n",
       "8410090                   None                                   None   \n",
       "8410091                   None                                   None   \n",
       "8410092                   None                                   None   \n",
       "8410093                   None                                   None   \n",
       "\n",
       "                                          landing_page_url  \\\n",
       "0        https://preprints.aijr.org/index.php/ap/prepri...   \n",
       "1        https://preprints.aijr.org/index.php/ap/prepri...   \n",
       "2        https://preprints.aijr.org/index.php/ap/prepri...   \n",
       "3        https://preprints.aijr.org/index.php/ap/prepri...   \n",
       "4        https://preprints.aijr.org/index.php/ap/prepri...   \n",
       "...                                                    ...   \n",
       "8410089              https://vixra.org/pdf/1409.0090v1.pdf   \n",
       "8410090                    https://vixra.org/abs/1112.0094   \n",
       "8410091              https://vixra.org/pdf/1406.0019v1.pdf   \n",
       "8410092              https://vixra.org/pdf/1306.0105v3.pdf   \n",
       "8410093              https://vixra.org/pdf/1412.0197v3.pdf   \n",
       "\n",
       "                                                     title  \\\n",
       "0        Bird’s Eye View on the Diagnosis, Treatment, &...   \n",
       "1        Doxycycline and Minocycline Drugs as a Treatme...   \n",
       "2        A Genetic Perspective of 2019-nCoV in Relation...   \n",
       "3        Marine Algae as a Natural Source for Antiviral...   \n",
       "4        Possible Prevention of COVID 19 by Using Linol...   \n",
       "...                                                    ...   \n",
       "8410089                 Three Objections to Modern Physics   \n",
       "8410090                               Particle Mass Ratios   \n",
       "8410091  Quantum FFF Theory Proposals for Some Unsolved...   \n",
       "8410092  Investigation of the Formalism of Particle Dyn...   \n",
       "8410093  Electromagnetic Energy and Electromagnetic For...   \n",
       "\n",
       "                                              authors_flat institutions_flat  \\\n",
       "0                              Panchalingala, Sai Bhargavi              None   \n",
       "1                                         Mostafa, Mohamed              None   \n",
       "2                                        Dasgupta, Rimjhim              None   \n",
       "3        Musale, Amar S; G., Raja Krishna Kumar; Sapre,...              None   \n",
       "4        Subhash, Venkata; G, Raja Krishna Kumar; Sapre...              None   \n",
       "...                                                    ...               ...   \n",
       "8410089                                      Lubomir Vlcek              None   \n",
       "8410090                                         DT Froedge              None   \n",
       "8410091                                           Leo Vuyk              None   \n",
       "8410092                                        Chi-Yi Chen              None   \n",
       "8410093                                    Yu.A. Spirichev              None   \n",
       "\n",
       "        countries_flat relations_json version_label is_version_of  \\\n",
       "0                 None           None          None                 \n",
       "1                 None           None          None                 \n",
       "2                 None           None          None                 \n",
       "3                 None           None          None                 \n",
       "4                 None           None          None                 \n",
       "...                ...            ...           ...           ...   \n",
       "8410089           None           None          None          None   \n",
       "8410090           None           None          None          None   \n",
       "8410091           None           None          None          None   \n",
       "8410092           None           None          None          None   \n",
       "8410093           None           None          None          None   \n",
       "\n",
       "        is_preprint_of has_preprint has_review has_published_version  \\\n",
       "0                                                              false   \n",
       "1                                                              false   \n",
       "2                                                              false   \n",
       "3                                                              false   \n",
       "4                                                              false   \n",
       "...                ...          ...        ...                   ...   \n",
       "8410089           None         None       None                  None   \n",
       "8410090           None         None       None                  None   \n",
       "8410091           None         None       None                  None   \n",
       "8410092           None         None       None                  None   \n",
       "8410093           None         None       None                  None   \n",
       "\n",
       "        published_version_ids_json version_of_ids_json update_to_json  \\\n",
       "0                             None                None           None   \n",
       "1                             None                None           None   \n",
       "2                             None                None           None   \n",
       "3                             None                None           None   \n",
       "4                             None                None           None   \n",
       "...                            ...                 ...            ...   \n",
       "8410089                       None                None           None   \n",
       "8410090                       None                None           None   \n",
       "8410091                       None                None           None   \n",
       "8410092                       None                None           None   \n",
       "8410093                       None                None           None   \n",
       "\n",
       "        raw_relationships_json records_hierarchy date_first_seen  \\\n",
       "0                         None            parent      2020-05-03   \n",
       "1                         None            parent      2020-04-25   \n",
       "2                         None            parent      2020-04-16   \n",
       "3                         None            parent      2020-04-15   \n",
       "4                         None            parent      2020-04-15   \n",
       "...                        ...               ...             ...   \n",
       "8410089                   None            parent      2014-09-01   \n",
       "8410090                   None            parent      2011-12-01   \n",
       "8410091                   None            parent      2014-06-01   \n",
       "8410092                   None            parent      2013-06-01   \n",
       "8410093                   None            parent      2014-12-01   \n",
       "\n",
       "         publication_year_first_seen parent_record_id records_hierarchy_copy  \\\n",
       "0                               2020             None                 parent   \n",
       "1                               2020             None                 parent   \n",
       "2                               2020             None                 parent   \n",
       "3                               2020             None                 parent   \n",
       "4                               2020             None                 parent   \n",
       "...                              ...              ...                    ...   \n",
       "8410089                         2014             None                 parent   \n",
       "8410090                         2011             None                 parent   \n",
       "8410091                         2014             None                 parent   \n",
       "8410092                         2013             None                 parent   \n",
       "8410093                         2014             None                 parent   \n",
       "\n",
       "        dup_group_id authors_fp_tokenbag  \\\n",
       "0               None                None   \n",
       "1               None     mohamed_mostafa   \n",
       "2               None    dasgupta_rimjhim   \n",
       "3               None                None   \n",
       "4               None                None   \n",
       "...              ...                 ...   \n",
       "8410089         None       lubomir_vlcek   \n",
       "8410090         None          dt_froedge   \n",
       "8410091         None            leo_vuyk   \n",
       "8410092         None         chen_chi_yi   \n",
       "8410093         None      a_spirichev_yu   \n",
       "\n",
       "                                            title_clean_v2  \\\n",
       "0                                                     None   \n",
       "1        doxycycline and minocycline drugs as a treatme...   \n",
       "2        a genetic perspective of 2019 ncov in relation...   \n",
       "3                                                     None   \n",
       "4                                                     None   \n",
       "...                                                    ...   \n",
       "8410089                 three objections to modern physics   \n",
       "8410090                               particle mass ratios   \n",
       "8410091  quantum fff theory proposals for some unsolved...   \n",
       "8410092  investigation of the formalism of particle dyn...   \n",
       "8410093  electromagnetic energy and electromagnetic for...   \n",
       "\n",
       "        authors_fp_last_initial authors_fp_last  \n",
       "0                          None            None  \n",
       "1                     mostafa|m            None  \n",
       "2                    dasgupta|r            None  \n",
       "3                          None            None  \n",
       "4                          None            None  \n",
       "...                         ...             ...  \n",
       "8410089                 vlcek|l            None  \n",
       "8410090               froedge|d            None  \n",
       "8410091                  vuyk|l            None  \n",
       "8410092                  chen|c            None  \n",
       "8410093             spirichev|y            None  \n",
       "\n",
       "[8410094 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(\"outputs/dedupe_data_out.parquet\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea05a7-6e5d-4c72-89ad-1b1c3429f149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f32cf834-5994-45e7-9a8d-d1d4075e7881",
   "metadata": {},
   "source": [
    "# dedupe on title+authors (+ optional year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d895e0-789d-401d-8f6f-bb2715533f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reproducible 2-pass dedupe pipeline (Exact pass -> Fuzzy pass) with:\n",
    "- Strong-but-cheap title normalization (cached)\n",
    "- 3 author signatures: tokenbag | last_initial | last\n",
    "- Stage A strict (title + authors_fp) exact\n",
    "- Stage B relaxed (shared authors overlap) within exact-title groups (optional per stage)\n",
    "- Optional fuzzy title fallback (token containment) BLOCKED by authors_fp (+ optional year)\n",
    "- Prefilter modes:\n",
    "    * title_dup  : keep rows where cleaned title repeats (fast exact stages)\n",
    "    * author_dup : keep rows where authors_fp repeats (enables fuzzy stages when titles differ)\n",
    "    * none       : keep all eligible (debug)\n",
    "\n",
    "Includes:\n",
    "- Metrics counters per stage\n",
    "- Summary printing + early stop\n",
    "- Deterministic labeling\n",
    "- Designed for speed + low false positives (especially with last_initial)\n",
    "\n",
    "USAGE:\n",
    "1) Define STAGES_EXACT and STAGES_FUZZY\n",
    "2) Run:\n",
    "   df_out, metrics = run_dedupe_pipeline_two_passes(\n",
    "       df,\n",
    "       stages_exact=STAGES_EXACT,\n",
    "       stages_fuzzy=STAGES_FUZZY,\n",
    "       early_stop_if_new_labels_lt=500,\n",
    "       print_summary=True,\n",
    "       return_all_metrics=True,\n",
    "       servers=None,\n",
    "       across_servers=True,\n",
    "       use_year=False,\n",
    "       choose_parent=\"oldest\",\n",
    "       prefilter=True,\n",
    "       date_candidates=('date_first_seen',),\n",
    "       hierarchy_col=\"records_hierarchy\",\n",
    "       parent_id_col=\"parent_record_id\",\n",
    "       group_id_col=\"dup_group_id\",\n",
    "       add_authors_fingerprint_col=True,\n",
    "       add_title_clean_col=True,\n",
    "   )\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import unicodedata\n",
    "from typing import Iterable, Optional, Dict, Any, Tuple, List\n",
    "\n",
    "# ============================================================\n",
    "# 0) Regex + NA helpers\n",
    "# ============================================================\n",
    "_WS = re.compile(r\"\\s+\")\n",
    "_PUNCT_ALL = re.compile(r\"[^\\w\\s]\", re.UNICODE)  # remove everything except word chars + spaces\n",
    "NA_LIKE = {\"\", \"none\", \"null\", \"nan\", \"n/a\", \"[]\", \"{}\", \"na\"}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Utility: pick a date column + record_id numeric fallback\n",
    "# ============================================================\n",
    "def _pick_first_existing(df: pd.DataFrame, candidates: Iterable[str]) -> Optional[str]:\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def _record_id_key(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Fast numeric key from record_id (extract first digits).\"\"\"\n",
    "    digits = s.astype(\"string\").str.extract(r\"(\\d+)\")[0]\n",
    "    return pd.to_numeric(digits, errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Title normalization (cheap, high ROI) + token containment\n",
    "# ============================================================\n",
    "def _strip_accents_text(x: str) -> str:\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFKD\", x) if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "\n",
    "def _clean_title_series_v2(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Strong-but-cheap title normalization:\n",
    "      - lowercase\n",
    "      - strip accents\n",
    "      - remove punctuation -> spaces\n",
    "      - collapse whitespace\n",
    "    \"\"\"\n",
    "    s = s.astype(\"string\").fillna(\"\").str.strip().str.lower()\n",
    "    s = s.where(~s.isin(list(NA_LIKE)), \"\")\n",
    "    s = s.apply(_strip_accents_text)\n",
    "    s = s.str.replace(_PUNCT_ALL, \" \", regex=True)\n",
    "    s = s.str.replace(_WS, \" \", regex=True).str.strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _title_tokens_from_clean(title_clean: str) -> List[str]:\n",
    "    \"\"\"Tokenize already-clean title into tokens; drop very short tokens (len < 2).\"\"\"\n",
    "    if not title_clean:\n",
    "        return []\n",
    "    return [t for t in title_clean.split(\" \") if len(t) >= 2]\n",
    "\n",
    "\n",
    "def _containment_score(a_tokens: List[str], b_tokens: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Containment score:\n",
    "        |A ∩ B| / min(|A|, |B|)\n",
    "    Good for small title differences when tokens still mostly match.\n",
    "    \"\"\"\n",
    "    if not a_tokens or not b_tokens:\n",
    "        return 0.0\n",
    "    A, B = set(a_tokens), set(b_tokens)\n",
    "    denom = min(len(A), len(B))\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    return len(A & B) / denom\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Author canonicalization (3 modes)\n",
    "# ============================================================\n",
    "def _strip_accents(s: str) -> str:\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c)\n",
    "    )\n",
    "\n",
    "\n",
    "def _normalize_one_author_tokenbag(author: str) -> str:\n",
    "    \"\"\"\n",
    "    Token-bag per author:\n",
    "    - remove punctuation\n",
    "    - split tokens\n",
    "    - sort tokens within author\n",
    "    - join with \"_\"\n",
    "    \"\"\"\n",
    "    if not author:\n",
    "        return \"\"\n",
    "    a = _strip_accents(str(author)).lower().strip()\n",
    "    if not a or a in NA_LIKE:\n",
    "        return \"\"\n",
    "    a = _PUNCT_ALL.sub(\" \", a)\n",
    "    a = _WS.sub(\" \", a).strip()\n",
    "    if not a:\n",
    "        return \"\"\n",
    "    toks = [t for t in a.split(\" \") if t]\n",
    "    if not toks:\n",
    "        return \"\"\n",
    "    toks = sorted(toks)\n",
    "    return \"_\".join(toks)\n",
    "\n",
    "\n",
    "def _normalize_one_author_last_initial(author: str) -> str:\n",
    "    \"\"\"\n",
    "    Middle-ground signature: \"last|first_initial\"\n",
    "    Rules:\n",
    "      - If comma: \"Last, First ...\" -> last = first token before comma;\n",
    "                                     initial = first token after comma (first-name token only)\n",
    "      - If no comma: \"First ... Last\" -> last = last token; initial = first token\n",
    "      - If we can't find an initial, return \"\" (reduces false positives)\n",
    "    \"\"\"\n",
    "    if not author:\n",
    "        return \"\"\n",
    "    a = _strip_accents(str(author)).lower().strip()\n",
    "    if not a or a in NA_LIKE:\n",
    "        return \"\"\n",
    "\n",
    "    if \",\" in a:\n",
    "        left, right = a.split(\",\", 1)\n",
    "        left = _PUNCT_ALL.sub(\" \", left)\n",
    "        right = _PUNCT_ALL.sub(\" \", right)\n",
    "        left = _WS.sub(\" \", left).strip()\n",
    "        right = _WS.sub(\" \", right).strip()\n",
    "        if not left:\n",
    "            return \"\"\n",
    "        last_toks = [t for t in left.split(\" \") if t]\n",
    "        if not last_toks:\n",
    "            return \"\"\n",
    "        last = last_toks[0]  # keep your \"first token if multi-token surname\" philosophy\n",
    "\n",
    "        first_toks = [t for t in right.split(\" \") if t]\n",
    "        if not first_toks:\n",
    "            return \"\"  # avoid false positives\n",
    "        ini = first_toks[0][:1]\n",
    "        return f\"{last}|{ini}\" if ini else \"\"\n",
    "    else:\n",
    "        a = _PUNCT_ALL.sub(\" \", a)\n",
    "        a = _WS.sub(\" \", a).strip()\n",
    "        toks = [t for t in a.split(\" \") if t]\n",
    "        if len(toks) < 2:\n",
    "            return \"\"\n",
    "        ini = toks[0][:1]\n",
    "        last = toks[-1]\n",
    "        return f\"{last}|{ini}\" if (ini and last) else \"\"\n",
    "\n",
    "\n",
    "def _normalize_one_author_last(author: str) -> str:\n",
    "    \"\"\"Last-name-only signature (high recall, more false positives).\"\"\"\n",
    "    if not author:\n",
    "        return \"\"\n",
    "    a = _strip_accents(str(author)).lower().strip()\n",
    "    if not a or a in NA_LIKE:\n",
    "        return \"\"\n",
    "\n",
    "    if \",\" in a:\n",
    "        left = a.split(\",\", 1)[0].strip()\n",
    "        left = _PUNCT_ALL.sub(\" \", left)\n",
    "        left = _WS.sub(\" \", left).strip()\n",
    "        if not left:\n",
    "            return \"\"\n",
    "        toks = [t for t in left.split(\" \") if t]\n",
    "        if not toks:\n",
    "            return \"\"\n",
    "        return toks[0]\n",
    "    else:\n",
    "        a = _PUNCT_ALL.sub(\" \", a)\n",
    "        a = _WS.sub(\" \", a).strip()\n",
    "        toks = [t for t in a.split(\" \") if t]\n",
    "        if not toks:\n",
    "            return \"\"\n",
    "        return toks[-1]\n",
    "\n",
    "\n",
    "def build_authors_fingerprint_series(authors_flat: pd.Series, mode: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Build author fingerprint per row:\n",
    "      - split authors on ';'\n",
    "      - normalize each author (depends on mode)\n",
    "      - drop empties\n",
    "      - dedupe within row\n",
    "      - sort\n",
    "      - join with ';'\n",
    "    \"\"\"\n",
    "    if mode not in {\"tokenbag\", \"last_initial\", \"last\"}:\n",
    "        raise ValueError(\"mode must be tokenbag | last_initial | last\")\n",
    "\n",
    "    s = authors_flat.astype(\"string\").fillna(\"\").str.strip()\n",
    "    s = s.where(~s.str.lower().isin(list(NA_LIKE)), \"\")\n",
    "\n",
    "    if mode == \"tokenbag\":\n",
    "        norm_fn = _normalize_one_author_tokenbag\n",
    "    elif mode == \"last_initial\":\n",
    "        norm_fn = _normalize_one_author_last_initial\n",
    "    else:\n",
    "        norm_fn = _normalize_one_author_last\n",
    "\n",
    "    def row_to_fp(x: str) -> str:\n",
    "        if not x:\n",
    "            return \"\"\n",
    "        authors = [a.strip() for a in str(x).split(\";\") if a.strip()]\n",
    "        norm = [norm_fn(a) for a in authors]\n",
    "        norm = [z for z in norm if z]\n",
    "        norm = sorted(set(norm))\n",
    "        return \";\".join(norm)\n",
    "\n",
    "    return s.apply(row_to_fp)\n",
    "\n",
    "\n",
    "def _author_tokens_from_fp(fp: str) -> List[str]:\n",
    "    if not fp:\n",
    "        return []\n",
    "    return [t for t in fp.split(\";\") if t]\n",
    "\n",
    "\n",
    "def _overlap_count(a_tokens: List[str], b_tokens: List[str]) -> int:\n",
    "    if not a_tokens or not b_tokens:\n",
    "        return 0\n",
    "    return len(set(a_tokens) & set(b_tokens))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Single-stage dedupe:\n",
    "#    - Prefilter (title_dup/author_dup/none)\n",
    "#    - Stage A strict (title + authors_fp) exact match\n",
    "#    - Optional fuzzy title fallback (within same authors_fp)\n",
    "#    - Optional Stage B relaxed (shared authors overlap) within exact-title groups\n",
    "# ============================================================\n",
    "def dedupe_title_authors_stage(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    # stage config\n",
    "    stage_name: str = \"stage\",\n",
    "    authors_fp_mode: str = \"tokenbag\",         # tokenbag | last_initial | last\n",
    "\n",
    "    # fuzzy config (title containment), executed only if enabled\n",
    "    title_fuzzy_fallback: bool = False,\n",
    "    min_title_tokens: int = 6,\n",
    "    min_title_containment: float = 0.70,\n",
    "    fuzzy_compare_strategy: str = \"parent_only\",  # parent_only | all_pairs_small (parent_only is safest/fastest)\n",
    "\n",
    "    # relaxed (shared authors overlap) config (exact title only)\n",
    "    relaxed_shared_authors: bool = True,\n",
    "    min_authors_required: int = 2,\n",
    "    min_shared_authors: int = 2,\n",
    "\n",
    "    # prefilter strategy (important!)\n",
    "    prefilter_mode: str = \"title_dup\",         # title_dup | author_dup | none\n",
    "    prefilter: bool = True,                    # if False, skip \">=2\" group filter (slower)\n",
    "\n",
    "    # global options\n",
    "    servers=None,\n",
    "    across_servers: bool = True,\n",
    "    use_year: bool = False,\n",
    "    choose_parent: str = \"oldest\",             # oldest | most_recent\n",
    "    overwrite_mode: str = \"parent_only\",       # any | parent_only | unlabeled_only\n",
    "\n",
    "    # columns\n",
    "    server_col: str = \"server_name\",\n",
    "    record_id_col: str = \"record_id\",\n",
    "    title_col: str = \"title\",\n",
    "    authors_col: str = \"authors_flat\",\n",
    "    year_col: str = \"publication_year_first_seen\",\n",
    "    date_candidates: Tuple[str, ...] = (\"date_first_seen\",),\n",
    "\n",
    "    hierarchy_col: str = \"records_hierarchy\",\n",
    "    parent_id_col: str = \"parent_record_id\",\n",
    "    group_id_col: str = \"dup_group_id\",\n",
    "\n",
    "    # caching/debug columns\n",
    "    add_authors_fingerprint_col: bool = True,\n",
    "    authors_fingerprint_col: str = \"authors_fp\",\n",
    "    add_title_clean_col: bool = True,\n",
    "    title_clean_col: str = \"title_clean_v2\",\n",
    "\n",
    "    return_metrics: bool = False,\n",
    ") -> pd.DataFrame | Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    One dedupe stage. Designed to be composed into a multi-stage pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    metrics: Dict[str, Any] = {\n",
    "        \"stage_name\": stage_name,\n",
    "        \"n_rows_df\": int(len(df)),\n",
    "        \"n_candidates_initial\": 0,\n",
    "        \"prefilter_mode\": prefilter_mode,\n",
    "        \"prefilter_rows\": 0,\n",
    "        \"prefilter_groups\": 0,\n",
    "        \"work_rows_after_keys\": 0,\n",
    "\n",
    "        \"stageA_groups\": 0,\n",
    "        \"stageA_children_labeled\": 0,\n",
    "\n",
    "        \"fuzzy_enabled\": bool(title_fuzzy_fallback),\n",
    "        \"fuzzy_groups\": 0,\n",
    "        \"fuzzy_pairs_checked\": 0,\n",
    "        \"fuzzy_children_labeled\": 0,\n",
    "\n",
    "        \"stageB_enabled\": bool(relaxed_shared_authors),\n",
    "        \"stageB_title_groups\": 0,\n",
    "        \"stageB_clusters\": 0,\n",
    "        \"stageB_children_labeled\": 0,\n",
    "\n",
    "        \"time_s\": 0.0,\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Ensure output cols exist\n",
    "    # ------------------------------------------------------\n",
    "    for c in (hierarchy_col, parent_id_col, group_id_col):\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "\n",
    "    if add_authors_fingerprint_col and authors_fingerprint_col not in df.columns:\n",
    "        df[authors_fingerprint_col] = pd.NA\n",
    "    if add_title_clean_col and title_clean_col not in df.columns:\n",
    "        df[title_clean_col] = pd.NA\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Eligibility\n",
    "    # ------------------------------------------------------\n",
    "    h = df[hierarchy_col]\n",
    "    if overwrite_mode == \"any\":\n",
    "        eligible = pd.Series(True, index=df.index)\n",
    "    elif overwrite_mode == \"parent_only\":\n",
    "        eligible = h.astype(\"string\").str.lower().str.strip().eq(\"parent\")\n",
    "    elif overwrite_mode == \"unlabeled_only\":\n",
    "        eligible = h.isna()\n",
    "    else:\n",
    "        raise ValueError(\"overwrite_mode must be any | parent_only | unlabeled_only\")\n",
    "\n",
    "    # server filter\n",
    "    if servers is None:\n",
    "        server_mask = pd.Series(True, index=df.index)\n",
    "    elif isinstance(servers, str):\n",
    "        server_mask = df[server_col].eq(servers)\n",
    "    else:\n",
    "        server_mask = df[server_col].isin(list(servers))\n",
    "\n",
    "    m = eligible & server_mask\n",
    "    metrics[\"n_candidates_initial\"] = int(m.sum())\n",
    "    if not m.any():\n",
    "        metrics[\"time_s\"] = time.perf_counter() - t0\n",
    "        return (df, metrics) if return_metrics else df\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Prefilter: decide which indices to consider in this stage\n",
    "    # ------------------------------------------------------\n",
    "    if prefilter_mode == \"title_dup\":\n",
    "        # title-based prefilter (fast for exact title stages)\n",
    "        t_clean = df.loc[m, title_clean_col] if (add_title_clean_col and title_clean_col in df.columns and df.loc[m, title_clean_col].notna().any()) else None\n",
    "        if t_clean is None:\n",
    "            t_clean = _clean_title_series_v2(df.loc[m, title_col])\n",
    "        vc = t_clean.value_counts()\n",
    "        keep_idx = t_clean[t_clean.isin(vc[vc >= 2].index)].index\n",
    "        metrics[\"prefilter_groups\"] = int((vc >= 2).sum())\n",
    "\n",
    "    elif prefilter_mode == \"author_dup\":\n",
    "        # author-fp based prefilter (crucial for fuzzy pass; titles may differ)\n",
    "        # compute fp only for m rows\n",
    "        a_fp = build_authors_fingerprint_series(df.loc[m, authors_col], mode=authors_fp_mode)\n",
    "        vc = a_fp.value_counts()\n",
    "        keep_idx = a_fp[a_fp.isin(vc[vc >= 2].index)].index\n",
    "        metrics[\"prefilter_groups\"] = int((vc >= 2).sum())\n",
    "\n",
    "    elif prefilter_mode == \"none\":\n",
    "        keep_idx = df.index[m]\n",
    "        metrics[\"prefilter_groups\"] = 0\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"prefilter_mode must be title_dup | author_dup | none\")\n",
    "\n",
    "    metrics[\"prefilter_rows\"] = int(len(keep_idx))\n",
    "    if len(keep_idx) == 0:\n",
    "        metrics[\"time_s\"] = time.perf_counter() - t0\n",
    "        return (df, metrics) if return_metrics else df\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Work subset + compute/attach cached normalization keys\n",
    "    # ------------------------------------------------------\n",
    "    cols_needed = [server_col, record_id_col, title_col, authors_col]\n",
    "    if use_year:\n",
    "        cols_needed.append(year_col)\n",
    "    date_col = _pick_first_existing(df, date_candidates)\n",
    "    if date_col:\n",
    "        cols_needed.append(date_col)\n",
    "\n",
    "    work = df.loc[keep_idx, cols_needed].copy()\n",
    "\n",
    "    # Title clean (cache to df if asked)\n",
    "    if add_title_clean_col:\n",
    "        # compute for missing only (cheap)\n",
    "        t_missing = df.loc[work.index, title_clean_col].isna()\n",
    "        if t_missing.any():\n",
    "            df.loc[work.index[t_missing], title_clean_col] = _clean_title_series_v2(df.loc[work.index[t_missing], title_col]).values\n",
    "        work[\"_t\"] = df.loc[work.index, title_clean_col].astype(\"string\").fillna(\"\")\n",
    "    else:\n",
    "        work[\"_t\"] = _clean_title_series_v2(work[title_col])\n",
    "\n",
    "    # Authors fp (mode-specific; cache into df column if asked)\n",
    "    work[\"_a_fp\"] = build_authors_fingerprint_series(work[authors_col], mode=authors_fp_mode)\n",
    "    if add_authors_fingerprint_col:\n",
    "        df.loc[work.index, authors_fingerprint_col] = work[\"_a_fp\"].values\n",
    "\n",
    "    # Year (optional)\n",
    "    if use_year:\n",
    "        y = pd.to_numeric(work[year_col], errors=\"coerce\")\n",
    "        y = y.where((y >= 1000) & (y <= 3000)).round().astype(\"Int64\")\n",
    "        work[\"_y\"] = y\n",
    "    else:\n",
    "        work[\"_y\"] = pd.NA\n",
    "\n",
    "    # require non-empty keys\n",
    "    if use_year:\n",
    "        work = work[(work[\"_t\"] != \"\") & (work[\"_a_fp\"] != \"\") & work[\"_y\"].notna()].copy()\n",
    "    else:\n",
    "        work = work[(work[\"_t\"] != \"\") & (work[\"_a_fp\"] != \"\")].copy()\n",
    "\n",
    "    metrics[\"work_rows_after_keys\"] = int(len(work))\n",
    "    if work.empty:\n",
    "        metrics[\"time_s\"] = time.perf_counter() - t0\n",
    "        return (df, metrics) if return_metrics else df\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Stage A STRICT: exact match on (title_clean + authors_fp [+year] [+server scope])\n",
    "    # ------------------------------------------------------\n",
    "    if use_year:\n",
    "        strict_base = work[\"_t\"] + \"||\" + work[\"_a_fp\"] + \"||\" + work[\"_y\"].astype(\"string\")\n",
    "    else:\n",
    "        strict_base = work[\"_t\"] + \"||\" + work[\"_a_fp\"]\n",
    "\n",
    "    if across_servers:\n",
    "        work[\"_grp_strict\"] = strict_base\n",
    "    else:\n",
    "        work[\"_grp_strict\"] = work[server_col].astype(\"string\") + \"||\" + strict_base\n",
    "\n",
    "    strict = work\n",
    "    if prefilter:\n",
    "        vcg = work[\"_grp_strict\"].value_counts()\n",
    "        dup_keys = vcg[vcg >= 2].index\n",
    "        strict = work[work[\"_grp_strict\"].isin(dup_keys)].copy()\n",
    "\n",
    "    metrics[\"stageA_groups\"] = int(strict[\"_grp_strict\"].nunique()) if not strict.empty else 0\n",
    "\n",
    "    # sort keys for parent choice\n",
    "    if date_col and date_col in strict.columns:\n",
    "        strict[\"_dt\"] = pd.to_datetime(strict[date_col], errors=\"coerce\")\n",
    "    else:\n",
    "        strict[\"_dt\"] = pd.NaT\n",
    "    strict[\"_rid\"] = _record_id_key(strict[record_id_col])\n",
    "\n",
    "    if not strict.empty:\n",
    "        if choose_parent == \"oldest\":\n",
    "            strict = strict.sort_values(\n",
    "                by=[\"_grp_strict\", \"_dt\", \"_rid\"],\n",
    "                ascending=[True, True, True],\n",
    "                na_position=\"last\",\n",
    "            )\n",
    "        elif choose_parent == \"most_recent\":\n",
    "            strict = strict.sort_values(\n",
    "                by=[\"_grp_strict\", \"_dt\", \"_rid\"],\n",
    "                ascending=[True, False, False],\n",
    "                na_position=\"last\",\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"choose_parent must be oldest | most_recent\")\n",
    "\n",
    "        parents = strict.groupby(\"_grp_strict\", sort=False).head(1)\n",
    "        parent_rid_map = parents.set_index(\"_grp_strict\")[record_id_col]\n",
    "        parent_srv_map = parents.set_index(\"_grp_strict\")[server_col]\n",
    "\n",
    "        strict[\"_parent_rid\"] = strict[\"_grp_strict\"].map(parent_rid_map)\n",
    "        strict[\"_parent_srv\"] = strict[\"_grp_strict\"].map(parent_srv_map)\n",
    "\n",
    "        is_parent = strict[record_id_col].eq(strict[\"_parent_rid\"])\n",
    "        parent_idx = strict.index[is_parent]\n",
    "        child_idx = strict.index[~is_parent]\n",
    "\n",
    "        metrics[\"stageA_children_labeled\"] = int(len(child_idx))\n",
    "\n",
    "        df.loc[parent_idx, hierarchy_col] = \"parent\"\n",
    "        df.loc[parent_idx, parent_id_col] = pd.NA\n",
    "        df.loc[child_idx, hierarchy_col] = (\n",
    "            \"parent - duplicate (\" + strict.loc[child_idx, \"_parent_srv\"].astype(\"string\") + \")\"\n",
    "        )\n",
    "        df.loc[child_idx, parent_id_col] = strict.loc[child_idx, \"_parent_rid\"].values\n",
    "\n",
    "        # deterministic group id\n",
    "        df.loc[strict.index, group_id_col] = (\n",
    "            pd.util.hash_pandas_object(strict[\"_grp_strict\"], index=False)\n",
    "            .astype(\"uint64\")\n",
    "            .astype(str)\n",
    "            .values\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Fuzzy title fallback (BLOCKED by authors_fp [+year], only remaining eligible)\n",
    "    # Important: this can find near-duplicate titles because we do NOT rely on title_dup.\n",
    "    # ------------------------------------------------------\n",
    "    if title_fuzzy_fallback:\n",
    "        # remaining eligible after Stage A\n",
    "        h2 = df[hierarchy_col]\n",
    "        if overwrite_mode == \"parent_only\":\n",
    "            eligible2 = h2.astype(\"string\").str.lower().str.strip().eq(\"parent\")\n",
    "        elif overwrite_mode == \"unlabeled_only\":\n",
    "            eligible2 = h2.isna()\n",
    "        else:\n",
    "            eligible2 = pd.Series(True, index=df.index)\n",
    "\n",
    "        remain_idx = work.index.intersection(df.index[eligible2])\n",
    "        wF = work.loc[remain_idx].copy()\n",
    "\n",
    "        if not wF.empty:\n",
    "            # block by authors_fp (+year) because authors are \"more trustworthy\"\n",
    "            if use_year:\n",
    "                wF[\"_grp_auth\"] = wF[\"_a_fp\"] + \"||\" + wF[\"_y\"].astype(\"string\")\n",
    "            else:\n",
    "                wF[\"_grp_auth\"] = wF[\"_a_fp\"]\n",
    "\n",
    "            # keep only blocks with >=2 rows\n",
    "            vc_auth = wF[\"_grp_auth\"].value_counts()\n",
    "            keep_auth = vc_auth[vc_auth >= 2].index\n",
    "            wF = wF[wF[\"_grp_auth\"].isin(keep_auth)].copy()\n",
    "\n",
    "            metrics[\"fuzzy_groups\"] = int(wF[\"_grp_auth\"].nunique()) if not wF.empty else 0\n",
    "\n",
    "            if not wF.empty:\n",
    "                # date/rid for parent selection\n",
    "                if date_col and date_col in wF.columns:\n",
    "                    wF[\"_dt\"] = pd.to_datetime(wF[date_col], errors=\"coerce\")\n",
    "                else:\n",
    "                    wF[\"_dt\"] = pd.NaT\n",
    "                wF[\"_rid\"] = _record_id_key(wF[record_id_col])\n",
    "\n",
    "                # tokens cache per row (within this stage)\n",
    "                tokens_map = {idx: _title_tokens_from_clean(wF.loc[idx, \"_t\"]) for idx in wF.index}\n",
    "\n",
    "                for grp, g in wF.groupby(\"_grp_auth\", sort=False):\n",
    "                    if len(g) < 2:\n",
    "                        continue\n",
    "\n",
    "                    # gate: ignore titles with too few tokens\n",
    "                    idxs = [idx for idx in g.index if len(tokens_map.get(idx, [])) >= min_title_tokens]\n",
    "                    if len(idxs) < 2:\n",
    "                        continue\n",
    "\n",
    "                    gg = g.loc[idxs].copy()\n",
    "                    if choose_parent == \"oldest\":\n",
    "                        gg = gg.sort_values(by=[\"_dt\", \"_rid\"], ascending=[True, True], na_position=\"last\")\n",
    "                    else:\n",
    "                        gg = gg.sort_values(by=[\"_dt\", \"_rid\"], ascending=[False, False], na_position=\"last\")\n",
    "\n",
    "                    if fuzzy_compare_strategy == \"parent_only\":\n",
    "                        parent_idx = gg.index[0]\n",
    "                        parent_tokens = tokens_map[parent_idx]\n",
    "                        parent_rid = gg.loc[parent_idx, record_id_col]\n",
    "                        parent_srv = gg.loc[parent_idx, server_col]\n",
    "\n",
    "                        # ensure parent labeled\n",
    "                        df.loc[parent_idx, hierarchy_col] = \"parent\"\n",
    "                        df.loc[parent_idx, parent_id_col] = pd.NA\n",
    "\n",
    "                        for idx in gg.index[1:]:\n",
    "                            metrics[\"fuzzy_pairs_checked\"] += 1\n",
    "                            sc = _containment_score(parent_tokens, tokens_map[idx])\n",
    "                            if sc >= min_title_containment:\n",
    "                                df.loc[idx, hierarchy_col] = f\"parent - duplicate ({parent_srv})\"\n",
    "                                df.loc[idx, parent_id_col] = parent_rid\n",
    "                                df.loc[idx, group_id_col] = f\"fuzzy::{authors_fp_mode}::{grp}\"\n",
    "                                metrics[\"fuzzy_children_labeled\"] += 1\n",
    "\n",
    "                    elif fuzzy_compare_strategy == \"all_pairs_small\":\n",
    "                        # safer than global all-pairs; still can be heavy if blocks are large.\n",
    "                        # We'll cluster by greedy expansion (bounded within block).\n",
    "                        idxs2 = gg.index.tolist()\n",
    "                        used = set()\n",
    "                        for i in idxs2:\n",
    "                            if i in used:\n",
    "                                continue\n",
    "                            used.add(i)\n",
    "                            cluster = [i]\n",
    "                            for j in idxs2:\n",
    "                                if j in used:\n",
    "                                    continue\n",
    "                                metrics[\"fuzzy_pairs_checked\"] += 1\n",
    "                                sc = _containment_score(tokens_map[i], tokens_map[j])\n",
    "                                if sc >= min_title_containment:\n",
    "                                    used.add(j)\n",
    "                                    cluster.append(j)\n",
    "\n",
    "                            if len(cluster) >= 2:\n",
    "                                # choose parent (oldest/most recent) within cluster\n",
    "                                cldf = gg.loc[cluster].copy()\n",
    "                                if choose_parent == \"oldest\":\n",
    "                                    cldf = cldf.sort_values(by=[\"_dt\", \"_rid\"], ascending=[True, True], na_position=\"last\")\n",
    "                                else:\n",
    "                                    cldf = cldf.sort_values(by=[\"_dt\", \"_rid\"], ascending=[False, False], na_position=\"last\")\n",
    "\n",
    "                                p_idx = cldf.index[0]\n",
    "                                p_rid = cldf.loc[p_idx, record_id_col]\n",
    "                                p_srv = cldf.loc[p_idx, server_col]\n",
    "                                df.loc[p_idx, hierarchy_col] = \"parent\"\n",
    "                                df.loc[p_idx, parent_id_col] = pd.NA\n",
    "                                for cidx in cldf.index[1:]:\n",
    "                                    df.loc[cidx, hierarchy_col] = f\"parent - duplicate ({p_srv})\"\n",
    "                                    df.loc[cidx, parent_id_col] = p_rid\n",
    "                                    df.loc[cidx, group_id_col] = f\"fuzzy::{authors_fp_mode}::{grp}\"\n",
    "                                    metrics[\"fuzzy_children_labeled\"] += 1\n",
    "                    else:\n",
    "                        raise ValueError(\"fuzzy_compare_strategy must be parent_only | all_pairs_small\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Stage B RELAXED (shared authors overlap) within exact title groups\n",
    "    # ------------------------------------------------------\n",
    "    if relaxed_shared_authors:\n",
    "        h3 = df[hierarchy_col]\n",
    "        if overwrite_mode == \"parent_only\":\n",
    "            eligible3 = h3.astype(\"string\").str.lower().str.strip().eq(\"parent\")\n",
    "        elif overwrite_mode == \"unlabeled_only\":\n",
    "            eligible3 = h3.isna()\n",
    "        else:\n",
    "            eligible3 = pd.Series(True, index=df.index)\n",
    "\n",
    "        remain_idx = work.index.intersection(df.index[eligible3])\n",
    "        w2 = work.loc[remain_idx].copy()\n",
    "        if not w2.empty:\n",
    "            if use_year:\n",
    "                relaxed_base = w2[\"_t\"] + \"||\" + w2[\"_y\"].astype(\"string\")\n",
    "            else:\n",
    "                relaxed_base = w2[\"_t\"]\n",
    "\n",
    "            if across_servers:\n",
    "                w2[\"_grp_title\"] = relaxed_base\n",
    "            else:\n",
    "                w2[\"_grp_title\"] = w2[server_col].astype(\"string\") + \"||\" + relaxed_base\n",
    "\n",
    "            # keep only repeated titles\n",
    "            vc2 = w2[\"_grp_title\"].value_counts()\n",
    "            keep_groups = vc2[vc2 >= 2].index\n",
    "            w2 = w2[w2[\"_grp_title\"].isin(keep_groups)].copy()\n",
    "\n",
    "            metrics[\"stageB_title_groups\"] = int(w2[\"_grp_title\"].nunique()) if not w2.empty else 0\n",
    "\n",
    "            if not w2.empty:\n",
    "                w2[\"_a_tokens\"] = w2[\"_a_fp\"].apply(_author_tokens_from_fp)\n",
    "                w2[\"_a_n\"] = w2[\"_a_tokens\"].apply(len)\n",
    "\n",
    "                if date_col and date_col in w2.columns:\n",
    "                    w2[\"_dt\"] = pd.to_datetime(w2[date_col], errors=\"coerce\")\n",
    "                else:\n",
    "                    w2[\"_dt\"] = pd.NaT\n",
    "                w2[\"_rid\"] = _record_id_key(w2[record_id_col])\n",
    "\n",
    "                group_counter = 0\n",
    "                children_total = 0\n",
    "\n",
    "                for grp, g in w2.groupby(\"_grp_title\", sort=False):\n",
    "                    if len(g) < 2:\n",
    "                        continue\n",
    "\n",
    "                    g = g[g[\"_a_n\"] >= min_authors_required].copy()\n",
    "                    if len(g) < 2:\n",
    "                        continue\n",
    "\n",
    "                    idxs = g.index.tolist()\n",
    "                    used = set()\n",
    "                    clusters = []\n",
    "\n",
    "                    # simple greedy clustering based on author overlap\n",
    "                    for i in idxs:\n",
    "                        if i in used:\n",
    "                            continue\n",
    "                        used.add(i)\n",
    "                        cl = [i]\n",
    "                        for j in idxs:\n",
    "                            if j in used:\n",
    "                                continue\n",
    "                            if _overlap_count(g.loc[i, \"_a_tokens\"], g.loc[j, \"_a_tokens\"]) >= min_shared_authors:\n",
    "                                used.add(j)\n",
    "                                cl.append(j)\n",
    "                        if len(cl) >= 2:\n",
    "                            clusters.append(cl)\n",
    "\n",
    "                    for cl in clusters:\n",
    "                        group_counter += 1\n",
    "                        cldf = g.loc[cl].copy()\n",
    "                        if choose_parent == \"oldest\":\n",
    "                            cldf = cldf.sort_values(by=[\"_dt\", \"_rid\"], ascending=[True, True], na_position=\"last\")\n",
    "                        else:\n",
    "                            cldf = cldf.sort_values(by=[\"_dt\", \"_rid\"], ascending=[False, False], na_position=\"last\")\n",
    "\n",
    "                        parent_idx = cldf.index[0]\n",
    "                        parent_rid = cldf.loc[parent_idx, record_id_col]\n",
    "                        parent_srv = cldf.loc[parent_idx, server_col]\n",
    "\n",
    "                        df.loc[parent_idx, hierarchy_col] = \"parent\"\n",
    "                        df.loc[parent_idx, parent_id_col] = pd.NA\n",
    "                        df.loc[parent_idx, group_id_col] = f\"relaxed::{stage_name}::{group_counter}\"\n",
    "\n",
    "                        child_idxs = [x for x in cldf.index if x != parent_idx]\n",
    "                        children_total += len(child_idxs)\n",
    "\n",
    "                        df.loc[child_idxs, hierarchy_col] = f\"parent - duplicate ({parent_srv})\"\n",
    "                        df.loc[child_idxs, parent_id_col] = parent_rid\n",
    "                        df.loc[child_idxs, group_id_col] = f\"relaxed::{stage_name}::{group_counter}\"\n",
    "\n",
    "                metrics[\"stageB_clusters\"] = int(group_counter)\n",
    "                metrics[\"stageB_children_labeled\"] = int(children_total)\n",
    "\n",
    "    metrics[\"time_s\"] = time.perf_counter() - t0\n",
    "    return (df, metrics) if return_metrics else df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Stage runner with summary + early stop\n",
    "# ============================================================\n",
    "def _count_children_labels(series: pd.Series) -> int:\n",
    "    s = series.astype(\"string\").fillna(\"\")\n",
    "    return int(s.str.startswith(\"parent - duplicate\").sum())\n",
    "\n",
    "\n",
    "def run_dedupe_stages(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    stages: List[Dict[str, Any]],\n",
    "    early_stop_if_new_labels_lt: int = 100,\n",
    "    print_summary: bool = True,\n",
    "    return_all_metrics: bool = True,\n",
    "    # common kwargs passed to every stage\n",
    "    **common_kwargs,\n",
    ") -> Tuple[pd.DataFrame, List[Dict[str, Any]]] | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs a list of stages sequentially with:\n",
    "      - delta duplicates added per stage\n",
    "      - early stop\n",
    "    \"\"\"\n",
    "    df_out = df\n",
    "    metrics_all: List[Dict[str, Any]] = []\n",
    "\n",
    "    prev_children = _count_children_labels(df_out[common_kwargs.get(\"hierarchy_col\", \"records_hierarchy\")])\n",
    "\n",
    "    for stage in stages:\n",
    "        name = stage.get(\"name\", stage.get(\"stage_name\", \"stage\"))\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        df_out, m = dedupe_title_authors_stage(\n",
    "            df_out,\n",
    "            return_metrics=True,\n",
    "            stage_name=name,\n",
    "            **common_kwargs,\n",
    "            **{k: v for k, v in stage.items() if k not in {\"name\", \"stage_name\"}},\n",
    "        )\n",
    "\n",
    "        now_children = _count_children_labels(df_out[common_kwargs.get(\"hierarchy_col\", \"records_hierarchy\")])\n",
    "        delta = now_children - prev_children\n",
    "        prev_children = now_children\n",
    "\n",
    "        m[\"stage_runtime_s\"] = time.perf_counter() - t0\n",
    "        m[\"new_children_added\"] = int(delta)\n",
    "        metrics_all.append(m)\n",
    "\n",
    "        if print_summary:\n",
    "            print(\n",
    "                f\"[{name}] new_children={delta} | \"\n",
    "                f\"cand={m['n_candidates_initial']} | \"\n",
    "                f\"prefilter_rows={m['prefilter_rows']} | \"\n",
    "                f\"A_children={m['stageA_children_labeled']} | \"\n",
    "                f\"fuzzy_children={m['fuzzy_children_labeled']} | \"\n",
    "                f\"B_children={m['stageB_children_labeled']} | \"\n",
    "                f\"time={m['stage_runtime_s']:.2f}s\"\n",
    "            )\n",
    "\n",
    "        if delta < early_stop_if_new_labels_lt:\n",
    "            if print_summary:\n",
    "                print(f\"Early stop after {name}: delta {delta} < {early_stop_if_new_labels_lt}\")\n",
    "            break\n",
    "\n",
    "    return (df_out, metrics_all) if return_all_metrics else df_out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Two-pass pipeline: Exact pass -> Fuzzy pass on remaining parents\n",
    "# ============================================================\n",
    "def run_dedupe_pipeline_two_passes(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    stages_exact: List[Dict[str, Any]],\n",
    "    stages_fuzzy: List[Dict[str, Any]],\n",
    "    early_stop_if_new_labels_lt: int = 100,\n",
    "    print_summary: bool = True,\n",
    "    return_all_metrics: bool = True,\n",
    "    **common_kwargs,\n",
    ") -> Tuple[pd.DataFrame, List[Dict[str, Any]]] | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pass A: run stages_exact (typically no fuzzy, prefilter_mode=title_dup).\n",
    "    Pass B: run stages_fuzzy (fuzzy enabled, prefilter_mode=author_dup), on remaining parents only.\n",
    "\n",
    "    IMPORTANT:\n",
    "      - For Pass A, it is normal to use overwrite_mode=\"any\" for stage1, then \"parent_only\" for stage2-3.\n",
    "      - For Pass B, use overwrite_mode=\"parent_only\" so we only touch unresolved parents.\n",
    "    \"\"\"\n",
    "    all_metrics: List[Dict[str, Any]] = []\n",
    "    df_out = df\n",
    "\n",
    "    if print_summary:\n",
    "        print(\"\\n=== PASS A: EXACT ===\")\n",
    "\n",
    "    df_out, mA = run_dedupe_stages(\n",
    "        df_out,\n",
    "        stages=stages_exact,\n",
    "        early_stop_if_new_labels_lt=early_stop_if_new_labels_lt,\n",
    "        print_summary=print_summary,\n",
    "        return_all_metrics=True,\n",
    "        **common_kwargs,\n",
    "    )\n",
    "    all_metrics.extend(mA)\n",
    "\n",
    "    if print_summary:\n",
    "        print(\"\\n=== PASS B: FUZZY (remaining parents) ===\")\n",
    "\n",
    "    df_out, mB = run_dedupe_stages(\n",
    "        df_out,\n",
    "        stages=stages_fuzzy,\n",
    "        early_stop_if_new_labels_lt=early_stop_if_new_labels_lt,\n",
    "        print_summary=print_summary,\n",
    "        return_all_metrics=True,\n",
    "        **common_kwargs,\n",
    "    )\n",
    "    all_metrics.extend(mB)\n",
    "\n",
    "    return (df_out, all_metrics) if return_all_metrics else df_out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Default stage configs (recommended)\n",
    "# ============================================================\n",
    "\n",
    "# PASS A (EXACT) — fast + high precision\n",
    "STAGES_EXACT = [\n",
    "    dict(\n",
    "        name=\"A1_tokenbag_exact\",\n",
    "        authors_fp_mode=\"tokenbag\",\n",
    "        prefilter_mode=\"title_dup\",\n",
    "        title_fuzzy_fallback=False,\n",
    "        relaxed_shared_authors=True,\n",
    "        min_authors_required=1,\n",
    "        min_shared_authors=1,\n",
    "        overwrite_mode=\"parent_only\",\n",
    "        authors_fingerprint_col=\"authors_fp_tokenbag\",\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"A2_last_initial_exact\",\n",
    "        authors_fp_mode=\"last_initial\",\n",
    "        prefilter_mode=\"title_dup\",\n",
    "        title_fuzzy_fallback=False,\n",
    "        relaxed_shared_authors=True,\n",
    "        min_authors_required=1,\n",
    "        min_shared_authors=1,\n",
    "        overwrite_mode=\"parent_only\",\n",
    "        authors_fingerprint_col=\"authors_fp_last_initial\",\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"A3_last_exact_strict\",\n",
    "        authors_fp_mode=\"last\",\n",
    "        prefilter_mode=\"title_dup\",\n",
    "        title_fuzzy_fallback=False,\n",
    "        relaxed_shared_authors=False,  # last-only already high recall; keep strict\n",
    "        overwrite_mode=\"parent_only\",\n",
    "        authors_fingerprint_col=\"authors_fp_last\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# PASS B (FUZZY) — only remaining parents; block by authors_fp repetition\n",
    "# Note: relaxed_shared_authors is usually OFF here to keep false positives down.\n",
    "STAGES_FUZZY = [\n",
    "    dict(\n",
    "        name=\"B1_tokenbag_fuzzy\",\n",
    "        authors_fp_mode=\"tokenbag\",\n",
    "        prefilter_mode=\"author_dup\",\n",
    "        title_fuzzy_fallback=True,\n",
    "        min_title_tokens=6,\n",
    "        min_title_containment=0.50,  # start conservative; lower = more recall, more risk\n",
    "        fuzzy_compare_strategy=\"parent_only\",\n",
    "        relaxed_shared_authors=False,\n",
    "        # min_authors_required=1,\n",
    "        # min_shared_authors=1,\n",
    "        overwrite_mode=\"parent_only\",\n",
    "        authors_fingerprint_col=\"authors_fp_tokenbag\",\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"B2_last_initial_fuzzy\",\n",
    "        authors_fp_mode=\"last_initial\",\n",
    "        prefilter_mode=\"author_dup\",\n",
    "        title_fuzzy_fallback=True,\n",
    "        min_title_tokens=6,\n",
    "        min_title_containment=0.70,\n",
    "        fuzzy_compare_strategy=\"parent_only\",\n",
    "        relaxed_shared_authors=False,\n",
    "        # min_authors_required=1,\n",
    "        # min_shared_authors=1,\n",
    "        overwrite_mode=\"parent_only\",\n",
    "        authors_fingerprint_col=\"authors_fp_last_initial\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 8) Example usage\n",
    "# ============================================================\n",
    "# df_out, metrics = run_dedupe_pipeline_two_passes(\n",
    "#     df,\n",
    "#     stages_exact=STAGES_EXACT,\n",
    "#     stages_fuzzy=STAGES_FUZZY,\n",
    "#     early_stop_if_new_labels_lt=500,\n",
    "#     print_summary=True,\n",
    "#     return_all_metrics=True,\n",
    "#     servers=None,\n",
    "#     across_servers=True,\n",
    "#     use_year=False,\n",
    "#     choose_parent=\"oldest\",\n",
    "#     prefilter=True,\n",
    "#     date_candidates=('date_first_seen',),\n",
    "#     hierarchy_col=\"records_hierarchy\",\n",
    "#     parent_id_col=\"parent_record_id\",\n",
    "#     group_id_col=\"dup_group_id\",\n",
    "#     add_authors_fingerprint_col=True,\n",
    "#     add_title_clean_col=True,\n",
    "#     title_clean_col=\"title_clean_v2\",\n",
    "# )\n",
    "#\n",
    "# print(metrics[-1])\n",
    "# print(df_out[\"records_hierarchy\"].value_counts(dropna=False).head(60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2702ca-ecf0-4602-a3fa-e2c5b79ca824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['records_hierarchy_copy2'] = data['records_hierarchy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43bfc87-a3eb-409b-90e3-7a82ce05c44b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "records_hierarchy_copy2\n",
       "parent                                                        7442983\n",
       "parent - duplicate (SSRN)                                      176436\n",
       "review                                                         152918\n",
       "part_of                                                        149382\n",
       "parent - duplicate (Zenodo)                                     94301\n",
       "parent - duplicate (arXiv)                                      61928\n",
       "parent - duplicate (Research Square)                            43399\n",
       "parent - duplicate (RePEc: Research Papers in Economics)        32214\n",
       "parent - duplicate (HAL)                                        30485\n",
       "parent - duplicate (bioRxiv)                                    26023\n",
       "version                                                         20174\n",
       "parent - duplicate (Open Science Framework)                     18028\n",
       "parent - duplicate (ResearchGate)                               15494\n",
       "parent - duplicate (AgEcon Search)                              14431\n",
       "parent - duplicate (Humanities Commons CORE)                    12702\n",
       "parent - duplicate (TechRxiv)                                   11909\n",
       "parent - duplicate (eLife)                                      11160\n",
       "parent - duplicate (Preprints.org)                               9570\n",
       "parent - duplicate (ChemRxiv)                                    9415\n",
       "parent - duplicate (PsyArXiv)                                    8360\n",
       "parent - duplicate (Qeios)                                       5782\n",
       "parent - duplicate (F1000Research)                               5197\n",
       "parent - duplicate (INA-Rxiv)                                    5089\n",
       "parent - duplicate (Authorea Inc.)                               3999\n",
       "parent - duplicate (EGUsphere)                                   3825\n",
       "parent - duplicate (Earth and Space Science Open Archive)        3596\n",
       "parent - duplicate (medRxiv)                                     3509\n",
       "parent - duplicate (SocArXiv)                                    3046\n",
       "parent - duplicate (EconStor Preprints)                          2614\n",
       "parent - duplicate (DSpace@MIT)                                  2110\n",
       "parent - duplicate (Nature Precedings)                           2101\n",
       "parent - duplicate (Advance)                                     1952\n",
       "publish_version                                                  1760\n",
       "parent - duplicate (viXra)                                       1488\n",
       "parent - duplicate (JMIR Preprints)                              1476\n",
       "parent - duplicate (Munich Personal RePEc Archive)               1440\n",
       "parent - duplicate (PeerJ Preprints)                             1220\n",
       "parent - duplicate (Wellcome Open Research)                      1150\n",
       "mirror (Open Science Framework)                                   902\n",
       "mirror (INA-Rxiv)                                                 883\n",
       "parent - duplicate (Cambridge Open Engage)                        762\n",
       "parent - duplicate (Thesis Commons)                               731\n",
       "mirror (arXiv)                                                    676\n",
       "mirror (PsyArXiv)                                                 655\n",
       "parent - duplicate (ScienceOpen Preprints)                        641\n",
       "parent - duplicate (EarthArXiv)                                   634\n",
       "mirror (SocArXiv)                                                 623\n",
       "parent - duplicate (Open Research Europe)                         590\n",
       "parent - duplicate (CERN document server)                         550\n",
       "parent - duplicate (Law Archive)                                  536\n",
       "mirror (AgEcon Search)                                            448\n",
       "parent - duplicate (Covid-19 Preprints)                           445\n",
       "parent - duplicate (engrXiv)                                      411\n",
       "parent - duplicate (IACR Cryptology ePrint Archive)               410\n",
       "child                                                             409\n",
       "mirror (Law Archive)                                              399\n",
       "parent - duplicate (EdArXiv)                                      375\n",
       "correction                                                        340\n",
       "parent - duplicate (HRB Open Research)                            318\n",
       "parent - duplicate (Social Science Open Access Repository)        303\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"records_hierarchy_copy2\"].value_counts(dropna=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92baedda-9e02-42ee-84ba-ab713ea45b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "records_hierarchy\n",
       "parent                                                        7442983\n",
       "parent - duplicate (SSRN)                                      176436\n",
       "review                                                         152918\n",
       "part_of                                                        149382\n",
       "parent - duplicate (Zenodo)                                     94301\n",
       "parent - duplicate (arXiv)                                      61928\n",
       "parent - duplicate (Research Square)                            43399\n",
       "parent - duplicate (RePEc: Research Papers in Economics)        32214\n",
       "parent - duplicate (HAL)                                        30485\n",
       "parent - duplicate (bioRxiv)                                    26023\n",
       "version                                                         20174\n",
       "parent - duplicate (Open Science Framework)                     18028\n",
       "parent - duplicate (ResearchGate)                               15494\n",
       "parent - duplicate (AgEcon Search)                              14431\n",
       "parent - duplicate (Humanities Commons CORE)                    12702\n",
       "parent - duplicate (TechRxiv)                                   11909\n",
       "parent - duplicate (eLife)                                      11160\n",
       "parent - duplicate (Preprints.org)                               9570\n",
       "parent - duplicate (ChemRxiv)                                    9415\n",
       "parent - duplicate (PsyArXiv)                                    8360\n",
       "parent - duplicate (Qeios)                                       5782\n",
       "parent - duplicate (F1000Research)                               5197\n",
       "parent - duplicate (INA-Rxiv)                                    5089\n",
       "parent - duplicate (Authorea Inc.)                               3999\n",
       "parent - duplicate (EGUsphere)                                   3825\n",
       "parent - duplicate (Earth and Space Science Open Archive)        3596\n",
       "parent - duplicate (medRxiv)                                     3509\n",
       "parent - duplicate (SocArXiv)                                    3046\n",
       "parent - duplicate (EconStor Preprints)                          2614\n",
       "parent - duplicate (DSpace@MIT)                                  2110\n",
       "parent - duplicate (Nature Precedings)                           2101\n",
       "parent - duplicate (Advance)                                     1952\n",
       "publish_version                                                  1760\n",
       "parent - duplicate (viXra)                                       1488\n",
       "parent - duplicate (JMIR Preprints)                              1476\n",
       "parent - duplicate (Munich Personal RePEc Archive)               1440\n",
       "parent - duplicate (PeerJ Preprints)                             1220\n",
       "parent - duplicate (Wellcome Open Research)                      1150\n",
       "mirror (Open Science Framework)                                   902\n",
       "mirror (INA-Rxiv)                                                 883\n",
       "parent - duplicate (Cambridge Open Engage)                        762\n",
       "parent - duplicate (Thesis Commons)                               731\n",
       "mirror (arXiv)                                                    676\n",
       "mirror (PsyArXiv)                                                 655\n",
       "parent - duplicate (ScienceOpen Preprints)                        641\n",
       "parent - duplicate (EarthArXiv)                                   634\n",
       "mirror (SocArXiv)                                                 623\n",
       "parent - duplicate (Open Research Europe)                         590\n",
       "parent - duplicate (CERN document server)                         550\n",
       "parent - duplicate (Law Archive)                                  536\n",
       "mirror (AgEcon Search)                                            448\n",
       "parent - duplicate (Covid-19 Preprints)                           445\n",
       "parent - duplicate (engrXiv)                                      411\n",
       "parent - duplicate (IACR Cryptology ePrint Archive)               410\n",
       "child                                                             409\n",
       "mirror (Law Archive)                                              399\n",
       "parent - duplicate (EdArXiv)                                      375\n",
       "correction                                                        340\n",
       "parent - duplicate (HRB Open Research)                            318\n",
       "parent - duplicate (Social Science Open Access Repository)        303\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"records_hierarchy\"].value_counts(dropna=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ece9ee-3f53-46d0-9947-8665629e829b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PASS A: EXACT ===\n",
      "[A1_tokenbag_exact] new_children=3 | cand=7442983 | prefilter_rows=58420 | A_children=0 | fuzzy_children=0 | B_children=3 | time=16.27s\n",
      "[A2_last_initial_exact] new_children=3 | cand=7442980 | prefilter_rows=58417 | A_children=0 | fuzzy_children=0 | B_children=3 | time=16.61s\n",
      "[A3_last_exact_strict] new_children=0 | cand=7442977 | prefilter_rows=58411 | A_children=0 | fuzzy_children=0 | B_children=0 | time=5.52s\n",
      "Early stop after A3_last_exact_strict: delta 0 < 1\n",
      "\n",
      "=== PASS B: FUZZY (remaining parents) ===\n"
     ]
    }
   ],
   "source": [
    "data_out, metrics = run_dedupe_pipeline_two_passes(\n",
    "    data,\n",
    "    stages_exact=STAGES_EXACT,\n",
    "    stages_fuzzy=STAGES_FUZZY,\n",
    "    early_stop_if_new_labels_lt=1,\n",
    "    print_summary=True,\n",
    "    return_all_metrics=True,\n",
    "    servers=None,\n",
    "    across_servers=True,\n",
    "    use_year=False,\n",
    "    choose_parent=\"oldest\",\n",
    "    prefilter=True,\n",
    "    date_candidates=('date_first_seen',),\n",
    "    hierarchy_col=\"records_hierarchy\",\n",
    "    parent_id_col=\"parent_record_id\",\n",
    "    group_id_col=\"dup_group_id\",\n",
    "    add_authors_fingerprint_col=True,\n",
    "    add_title_clean_col=True,\n",
    "    title_clean_col=\"title_clean_v2\",\n",
    ")\n",
    "\n",
    "print(metrics[-1])\n",
    "print(data_out[\"records_hierarchy\"].value_counts(dropna=False).head(60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885af22d-4728-4392-883e-c2549c72ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save metrics\n",
    "with open(OUT_DIR / \"dedupe_metrics_2.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "pd.DataFrame(metrics).to_csv(OUT_DIR / \"dedupe_metrics_2.csv\", index=False)\n",
    "\n",
    "# Save dataset\n",
    "data_out.to_parquet(OUT_DIR / \"dedupe_data_out_2.parquet\", index=False)\n",
    "\n",
    "print(\"✅ All files saved to outputs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78fbf8-2b4c-4b5b-a04d-cedebc9a995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "new_cols = [\n",
    "    \"records_hierarchy_copy2\",\n",
    "    \"records_hierarchy_copy\",\n",
    "    \"records_hierarchy\",\n",
    "    \"parent_record_id\",\n",
    "    \"dup_group_id\",\n",
    "    \"authors_fp_tokenbag\",\n",
    "    \"authors_fp_last_initial\",\n",
    "    \"authors_fp_last\",\n",
    "    \"title_clean_v2\",\n",
    "]\n",
    "# original_cols = set(df.columns)\n",
    "\n",
    "# detect new columns\n",
    "# new_cols = [c for c in data_out.columns if c not in original_cols]\n",
    "\n",
    "cols_to_save = [\"record_id\"] + new_cols\n",
    "\n",
    "data_out[cols_to_save].to_parquet(\n",
    "    OUT_DIR / \"dedupe_data_out_new_cols_2.parquet\",\n",
    "    index=False\n",
    ")\n",
    "data_out[cols_to_save].to_csv(\n",
    "    OUT_DIR / \"dedupe_data_out_new_cols_2.csv\",\n",
    "    index=False\n",
    ")\n",
    "print(\"✅ Saved:\", cols_to_save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098af1a8-01dd-404a-9e37-e863be02b083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6878884-b90d-4a11-9a5f-33fd4fb6bed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f29d0-ada1-457d-9eb9-3907f57bb852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571c69b-cc90-40d7-9f15-3b25025ffffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05595e98-abeb-406a-91cd-92148849a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_out[\"records_hierarchy_copy\"].value_counts(dropna=False).head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2dab6b-b2a8-4fd2-8c86-140100fdcbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_out[\"parent_record_id\"].value_counts(dropna=False).head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ec509-e92a-4df1-9563-f77d0ffeb607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = \"fuzzy::las\"\n",
    "\n",
    "\n",
    "mask = data_out['dup_group_id'].str.contains(pattern, regex=False, na=False)\n",
    "result = data_out[mask]\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063eef3a-23d5-4090-a60a-c6842e815eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['relations_json'][281751]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4c54d-614b-48a0-8b1c-6f44dbbb285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out[data_out[\"record_id\"]=='crossref::10.26434/chemrxiv-2021-cj17s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b235ee1-a86e-409f-b9b3-5103107f9a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_out[data_out[\"parent_record_id\"]=='crossref::10.26434/chemrxiv-2022-fd190']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6f270-3456-4a77-aaba-8095097cdde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = \"chemrxiv.11846943\"\n",
    "\n",
    "\n",
    "mask = data_out['doi'].str.contains(pattern, regex=False, na=False)\n",
    "result = data_out[mask]\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08cf10d-7082-4ab1-ba87-184097ba0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['records_hierarchy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a0595-69da-43b9-83a2-929fd57dff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f84bbe-0839-4611-928e-7d5e6689f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['authors_flat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72855d9-2873-49a8-ba3a-273861344e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"10.26434/chemrxiv-2022-fd190\"\n",
    "\n",
    "\n",
    "mask = data_out['doi'].str.contains(pattern, regex=False, na=False)\n",
    "result = data_out[mask]\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf1947-5cc4-475f-ba4a-21f9283dd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"10.26434/chemrxiv-2022-fd190\"\n",
    "\n",
    "\n",
    "mask = data['doi'].str.contains(pattern, regex=False, na=False)\n",
    "result = data[mask]\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939fe19-5459-41f6-8288-0720d2aa1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa0862-5cdb-4b96-8c81-1d4bba893f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['authors_flat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fbc53-af9d-41d5-a89c-bd5a84aa9864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f785af4-cb35-415e-8fb5-054723923431",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_titles = data_out.sample(5)[['title', 'authors_flat']].title\n",
    "data_out[data_out.title.isin(sample_titles)][['title','authors_flat','records_hierarchy','date_first_seen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7c407-e802-491c-8431-f4205e53c462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccb452-6c8e-4178-8d00-d4d7b85d8a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab49b06-99cc-46ce-b0f8-54318783f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"10.26434/chemrxiv.13102877\"\n",
    "\n",
    "\n",
    "mask = data_out['doi'].str.contains(pattern, regex=False, na=False)\n",
    "result = data_out[mask]\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab90c95-6db8-4ab5-95ac-b691176648ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e1441-d968-4a4a-be02-98c0d8349517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d746d-e237-4e9a-b670-64b62f69806a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584269d-645c-45ec-b786-2a4418c51695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (preprint-harvester)",
   "language": "python",
   "name": "preprint-harvester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
